{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "preprocess_using_colab_and_zip.ipynb",
      "provenance": [],
      "mount_file_id": "1-y-Wzi7b61nx8O2HXi3wBIfJfQtWfvDB",
      "authorship_tag": "ABX9TyPsYTUN3aLprbhuAvBKJvoy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stmeinert/Recolorization_IANN/blob/main/preprocess_using_colab_and_zip.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(os.getcwd())\n",
        "print(os.listdir(os.getcwd()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YlKgsmG69hyn",
        "outputId": "c7e663dd-217f-46ba-83e7-33da701f35b4"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "['.config', 'drive', 'sample_data']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# need to unzip my files\n",
        "import zipfile\n",
        "with zipfile.ZipFile('/content/drive/MyDrive/right_celeb_upload/img_align_celeba_zipped.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/unzip_celeb')"
      ],
      "metadata": {
        "id": "Z0eTpjx99c78"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rGLWZQfQ8iXA",
        "outputId": "aa13102d-756b-43ee-eaec-a51b462e9568"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of images in directory202599\n"
          ]
        }
      ],
      "source": [
        "import pathlib\n",
        "#directory of the image data for preprocessing\n",
        "data_dir = pathlib.Path('/content/unzip_celeb/img_align_celeba')\n",
        "image_count = len(list(data_dir.glob('*.jpg')))\n",
        "print('Number of images in directory' + str(image_count))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow-io"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Aa3KyxvC45s",
        "outputId": "0ba40f82-cc9d-45a9-d6e6-5b75e0a199b8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow-io\n",
            "  Downloading tensorflow_io-0.24.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (23.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 23.4 MB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow-io-gcs-filesystem==0.24.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-io) (0.24.0)\n",
            "Installing collected packages: tensorflow-io\n",
            "Successfully installed tensorflow-io-0.24.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = os.path.join(os.getcwd(), \"celeb_data_set_preprocessed_tiny_64_30000\")\n",
        "print('Path of the saved dataset file' + str(path))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xJgVUTLEIigo",
        "outputId": "3602546b-0fe4-442c-cb19-dbbefe18b75e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path of the saved dataset file/content/celeb_data_set_preprocessed_tiny_64_30000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import pathlib\n",
        "import tensorflow_io as tfio\n",
        "\n",
        "\n",
        "SIZE = (128,128)\n",
        "BATCH_SIZE = None # changed to just one\n",
        "\n",
        "#################################################\n",
        "# Prepare data\n",
        "#################################################\n",
        "\n",
        "def resize(image):\n",
        "    return tf.image.resize_with_pad(image, target_height=SIZE[0], target_width=SIZE[1], method=tf.image.ResizeMethod.BILINEAR)\n",
        "\n",
        "\n",
        "def to_lab(image):\n",
        "    # expects input to be normalized to [0;1]!!\n",
        "    # output channels are [l,a,b]\n",
        "    return tfio.experimental.color.rgb_to_lab(image)\n",
        "\n",
        "\n",
        "def to_grayscale(image):\n",
        "    # take l channel (size index starts at one^^)\n",
        "    image = tf.slice(image, begin=[0, 0, 0], size=[-1, -1, 1])\n",
        "    return image\n",
        "\n",
        "def prepare_image_data_just_pictures(image_ds):\n",
        "    # resize image to desired dimension, replace label with colored image\n",
        "    image_ds = image_ds.map(lambda x: (resize(x), resize(x)))\n",
        "\n",
        "    # normalize data to [0;1) for lab encoder\n",
        "    image_ds = image_ds.map(lambda image, target: ((image/256), (target/256)))\n",
        "\n",
        "    # convert image and target image to lab color space\n",
        "    image_ds = image_ds.map(lambda image, target: (to_lab(image), to_lab(target)))\n",
        "\n",
        "    # only take l channel of input tensor\n",
        "    image_ds = image_ds.map(lambda image, target: (to_grayscale(image), target))\n",
        "\n",
        "    # l in lab is in [0;100] -> normalize to [-1;1]\n",
        "    # ab are in range [-128;127]\n",
        "    image_ds = image_ds.map(lambda image, target: ((image/50)-1, target))\n",
        "\n",
        "    image_ds = image_ds.shuffle(1000).prefetch(20)\n",
        "    return image_ds\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#directory of the image data for preprocessing\n",
        "data_dir = pathlib.Path('/content/unzip_celeb/img_align_celeba')\n",
        "image_count = len(list(data_dir.glob('*.jpg')))\n",
        "print('Number of images in directory' + str(image_count))\n",
        "\n",
        "\n",
        "#create the dataset \n",
        "#inital size\n",
        "img_height = 218\n",
        "img_width = 178\n",
        "\n",
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  data_dir,\n",
        "  labels=None,\n",
        "  #changed from 0.7 to 0.85\n",
        "  validation_split=(0.85),\n",
        "  subset='training',\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=None)\n",
        "print('created data set')\n",
        "\n",
        "\n",
        "#apply preprocessing step\n",
        "\n",
        "train_ds = train_ds.apply(prepare_image_data_just_pictures)\n",
        "print('applied preprocessing')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# save the dataset\n",
        "# folder of the preprocessed data\n",
        "path = os.path.join(os.getcwd(), \"celeb_data_set_unbatch_30000\")\n",
        "# Save a dataset\n",
        "tf.data.experimental.save(train_ds, path,compression= 'GZIP')\n",
        "print('Path of the saved dataset file' + str(path))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ufbVsmJC61e",
        "outputId": "36c3374d-c5ee-495e-ad69-91ee2bd622f5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of images in directory202599\n",
            "Found 202599 files belonging to 1 classes.\n",
            "Using 30390 files for training.\n",
            "created data set\n",
            "applied preprocessing\n",
            "Path of the saved dataset file/content/celeb_data_set_unbatch_30000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/celeb_data_set_unbatch_30000.zip  /content/celeb_data_set_unbatch_30000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SAxmHdertZjh",
        "outputId": "33ade120-f288-4d6e-a9d7-10f1d83da9dc"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/celeb_data_set_unbatch_30000/ (stored 0%)\n",
            "  adding: content/celeb_data_set_unbatch_30000/snapshot.metadata (stored 0%)\n",
            "  adding: content/celeb_data_set_unbatch_30000/dataset_spec.pb (deflated 41%)\n",
            "  adding: content/celeb_data_set_unbatch_30000/2991326379668033694/ (stored 0%)\n",
            "  adding: content/celeb_data_set_unbatch_30000/2991326379668033694/00000000.shard/ (stored 0%)\n",
            "  adding: content/celeb_data_set_unbatch_30000/2991326379668033694/00000000.shard/00000000.snapshot (deflated 0%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /content/drive/MyDrive/celeb_data_set_unbatch_30000"
      ],
      "metadata": {
        "id": "t-YtsJiQzAPX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "babbb7e3-ec50-4ab5-c05a-a6e025c63593"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/content/drive/MyDrive/celeb_data_set_unbatch_30000’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/celeb_data_set_unbatch_30000.zip /content/drive/MyDrive/celeb_data_set_unbatch_30000/celeb_data_set_unbatch_30000.zip"
      ],
      "metadata": {
        "id": "pBX4_wB9xvAS"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -lh /content/celeb_data_set_unbatch_30000.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mEFS-48a0uWY",
        "outputId": "bb61a074-980f-4587-d3f5-ae5302a0dbe7"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-rw-r--r-- 1 root root 4.9G Mar 20 16:02 /content/celeb_data_set_unbatch_30000.zip\n"
          ]
        }
      ]
    }
  ]
}